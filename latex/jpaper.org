# #+TITLE: Notes About about the MPC journal paper
#+SETUPFILE: ~/.emacs.d/org-templates/level-0.org
#+PROPERTY: TEMPLATE page_math
#+PROPERTY: URL projects/mpc_j.html 
#+PROPERTY: SAVE_AS projects/mpc_j.html
#+OPTIONS: tex:t
#+STARTUP: latexpreview
#+TODO: TODO(t) WAITING(w@/!) | DONE(d@/!) CANCELED(c@/!) STARTED(s@/!) DEFERRED(ef@/!)
#+STARTUP: fold
#+STARTUP: lognotestate t
#+SEQ_TODO: TODO STARTED WAITING DELEGATED APPT | DONE DEFERRED CANCELLED
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{xspace, dsfont}
#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \newcommand{\Dm}{\ensuremath{\mathcal{D}_{-} }\xspace}
#+LATEX_HEADER:\newcommand{\U}{\ensuremath{\mathcal{U} }\xspace}
#+LATEX_HEADER:\newcommand{\DU}{\ensuremath{\Delta \mathcal{U} }\xspace}
#+LATEX_HEADER: \newcommand{\Q}{\ensuremath{\mathcal{Q} }\xspace}
#+LATEX_HEADER: \newcommand{\R}{\ensuremath{\mathcal{R} }\xspace}
#+LATEX_HEADER: \newcommand{\Hh}{\ensuremath{\mathcal{H} }\xspace}
#+LATEX_HEADER: \newcommand{\du}{\ensuremath{\Delta u }\xspace}
#+LATEX_HEADER: \newcommand{\dU}{\ensuremath{\Delta \mathcal{u} }\xspace}

#+LATEX_HEADER: \newcommand{\Gd}{\ensuremath{\tilde G }\xspace}
#+LATEX_HEADER: \newcommand{\Ad}{\ensuremath{\tilde A }\xspace}
#+LATEX_HEADER: \newcommand{\Bd}{\ensuremath{\tilde B }\xspace}
#+LATEX_HEADER: \newcommand{\Cd}{\ensuremath{\tilde C }\xspace}
#+LATEX_HEADER: \newcommand{\xd}{\ensuremath{\tilde \xi }\xspace}
#+LATEX_HEADER: \newcommand{\Qd}{\ensuremath{\tilde Q }\xspace}
#+LATEX_HEADER: \newcommand{\Rd}{\ensuremath{\tilde R }\xspace}

#+LATEX_HEADER: \newcommand{\x}{\ensuremath{\xi }\xspace}
#+LATEX_HEADER: \newcommand{\xdss}{\ensuremath{\tilde \xi_{ss} }\xspace}
#+LATEX_HEADER: \newcommand{\xde}{\ensuremath{\tilde \xi_{e} }\xspace}

#+LATEX_HEADER: \newcommand{\xo}{\ensuremath{\hat \xi }\xspace}
#+LATEX_HEADER: \newcommand{\yr}{\ensuremath{\nu_{r} }\xspace}
#+LATEX_HEADER: \newcommand{\y}{\ensuremath{\nu} \xspace}

#+LATEX_HEADER: \newcommand{\dd}{\ensuremath{\Delta }\xspace}

#+LATEX_HEADER: \newcommand{\ub}{\ensuremath{\bar{u} }\xspace}
#+LATEX_HEADER: \newcommand{\ubp}{\ensuremath{\bar{u}^+ }\xspace}
#+LATEX_HEADER: \newcommand{\ubm}{\ensuremath{\bar{u}^- }\xspace}


* Introduction

In the context of CS, we are interested in rapidly moving the AFM stage between setpoints. The setpoints define either discrete measurement locations or the start of a new $\mu$ -path scan. In earlier work, we found while exploring the limits of achievable with plain linear feedback that the change in the control input, $\Delta u(k)$ was the limiting factor. We  cite:braker_application_2017, cite:braker_fast_2017 took the viewpoint of trying to achieve a stable system for a equivalent given feedback gain in the face of rate-of change saturation. The methods we chose for doing this were using model predictive control (MPC) and tracking an optimal trajectory generated by solving a contrained, linear quadratic regulator problem (CLQR). In both cases, we considered a standard quadratic cost function

\begin{align}
V(z,v) &= \min_{v} z_{N}Q_{p}z_{N} + \sum_{i=0}^{N-1}z_{i}^{T}Qz_{i} + v^{T}_{i}Rv_{i}\\
 \text{s.t.}&\\
z_{i+1} &= Az_{i} + Bv_{i}\\
z_{0} &= x_{k}
|v(i) - v(i-1)| &= |\Delta v(i)| \leq (\Delta u)_{max}
\label{eqn:opt}
\end{align}


The essential difference between the MPC scheme and the trajectory tracking scheme is that the optimzition in MPC solved repetaly online, and the control input given to the system is $v(0)$. In the trajectory tracking scheme, the optimization is solved offline and the resulting optimal input trajectory is fed to the system in a feedforward manner while state feedback tracks the optimal state sequence. In both cases, the weight $Q, R)$ were chosen via an inverse optimal control problem, such that the associated linear feedback (in the infinite horizon, unconstrained LQR problem) would place the poles with the desired damping. 

It was our conclusion that both methods are effective at extending the stable range of a given $(Q,R)$ pair in the face of $\Delta u$ saturation. The attractiveness of MPC here is that it does not depend on defining a list a setpoints to visit a-priori. The downside to MPC is that to significantly expand the region of rechable setpoints requires a large control horizon. Our MPC implementation used the Fast Graident Method (FGM) to solve the quadratic program associated with \eqref{eqn:opt}. Unfortunately, the convergence rate of the FGM depends heavily on the condition number of the Hessian matrix of the QP. Several factors contribute to a poorly conditioned Hessian matrx: (1) long control horizon (2), aggressive (Q,R) weights. The other factor limiting the horizon length in MPC is that the problem size grows, making the QP more difficult to solve within the required sampletime. 

The question which naturually arises from our prior work and which is the main topic of this study, is "how much \emph{time}" is actually saved with either MPC or CLQR tracking?" In essence, the reachable set of setpoints using pure linear feedback can be expanded by de-rating the linear feedback gain. While we might expect this to result in a slower settling time, the question we seek to answer is \emph{how much slower}? In short, are the more complicated methods worth it?

A second related question is \emph{if you're going to go through the trouble of generating and tracking an optimal trajectory, why not track the time-optimal trajectory?}

We will answer both of these questions in this paper. 

* Preliminarys

In the optimizations we consider, it will often be useful to work with an incremental form of $G$ which has as its input ${\Delta u(k)\coloneqq u(k)-u(k-1)}$, rather than $u$, which is defined by augmenting $G_p$ with an state $\x_u(k) such that
\begin{equation*}
  \x_u(k) = u(k-1).
\end{equation*}
It follows that
\begin{subequations}
\begin{align}
  \xd(k+1)
  &=
    \begin{bmatrix}
      A & B\\ 0 & I
    \end{bmatrix}
    \xd(k)
    +
    \begin{bmatrix}
      B\\I
    \end{bmatrix}
  \Delta u(k) \\
  \y(k) & = \begin{bmatrix}C & 0\end{bmatrix}\xd(k)\\
  \xd(k)& \coloneqq \begin{bmatrix}\x(k)\\\x_u(k) \end{bmatrix}\\
  \xd(0) & = \begin{bmatrix}\x(0)\\u(-1)\end{bmatrix}. \label{eqn:x0_aug}
\end{align}\label{eqn:ssdelta}%
\end{subequations}
We call this system $\Gd = \{\Ad, \Bd, \Cd, 0\}$. To solve the setpoint tracking problem, we work in the error
coordinates of $\Gd$. 
For an arbitrary reference $\y_r$, in steady state we have ${\du_{ss}=0}$ and $\xdss =N_{\xi}\y_r$ where ${N_{\xi}\in\mathds{R}^{\tilde{n}_s\times n_u} }$ is found by solving
\begin{align}
  \begin{bmatrix}N_{\xi} \\ N_u\end{bmatrix} &=
\begin{bmatrix}I-\Ad & -\Bd\\\Cd & 0\end{bmatrix}^{-1}\begin{bmatrix}0\\ I\\\end{bmatrix}\label{eqn:nxnu},
\end{align}
which will give $N_u\equiv 0$.
The error state, ${\xde(k)=\xd(k) - \xdss}$ has dynamics
\begin{align}
  \xde(k+1) & = \Ad\xd(k) + \Bd\dd u(k) - \xdss \nonumber\\
            & = \Ad \xde(k)   + \Bd \dd u(k)\nonumber.
\end{align}



** Solving the time-optimal control problem in discrete-time 
In discrete-time, the minimum-time control problem can be stated as cite:chen_minimumtime_cca
\begin{align}
\min_{u(0), u(1),\dots,u(N-1)} & N\\
\text{s.t.}&\\
x_{k+1} & = Ax_{k} + Bu_{k}\\
x_{T} & = x_{f}\\
u_{k}&\in \mathcal{U},~k=0,\dots,N-1\\
x_{k} &\neq x_{f},~k=0,\dots,N-1.
\end{align}

More practically, the problem can be solved using a bisection method which searches for the smallest feasible $N$. In these cases, the bisection search solves sub-problem given by


\begin{align}
\min_{U} || x_{f} - x_{N}||\\
\text{s.t.} &\\
x_{k+1} & = Ax_{k} + Bu_{k}\\
u_{k}&\in \mathcal{U},~k=0,\dots,N-1\\
\end{align}

For a given $N$, if $||x_{f} - x_{N}|| < \text{TOL}$, the subproblem returns succseful, otherwise it fails. The goal then is to find a the smallest $N$ that succeeds. 

It is also worth pointing out that the solution to this problem, in contrast to continuous time systems is not in general bang-bang CITE.


* Quantifying the time savings (if any) of MPC and d-rated linear feedback
I have been trying to figure out how to quantify the time savings (if any) of using MPC vs a de-rated, saturated linear feedback. The basic idea is:

1. We start with a nominal $(Q,R)$ pair.
2. We determine how large we must make $\gamma R$ to visit a certain size of setpoint. In general, the larger $\gamma$ is, the larger the maximum setpoint we can visit is. This is what I mean by "de-rating" the feedback gain and is illustrated below in Figur.


Note that each point in that plot was generated by simulated the linear feedback law with saturation starting from a very small setpoint and incrementing larger (by 0.1 I think) until the output becomes unstable. 

So the questions I want to answer are:
1. Given a maximum setpoint $ref_{max}$, how much time do we *loose* by making $\gamma$ large? Said another way, what is the time penalalty for needing to visit larger setpoints (since this implies that $K$ must be "smaller")?
2. How does this time compare to what we can acheive with MPC?

The reason the second question is tricky is that we cannot implement MPC with an arbitrarily long time horizon. Nonetheless, lets think about the first question first. 

The way I think it makes sense to think about these questions is to compare the settling times to the optimal, constrained finite horizon (CLQR) open-loop settling time. At least for a given quadratic cost, that is the best settling time we can hope to achieve, and we won't run into the problems with MPC where need a larger control horizon to get stability. 

The point is: *Use the open-loop CLQR trajectoy as the baseline for all comparisons*



#+BEGIN_SEXP
(figure ()
        (subfigure '("Left graph from sexp." (label "fig:sa"))
                   (includesvg '((width . "3in"))
                                    "figures/maxref_vs_gamma_dumaxp6.svg"))
        (enskip)
        (subfigure '("Right graph from sexp" (label "fig:sb"))
                   (includesvg '((width . "3in"))
                                    "figures/clqrTimeOpt_sp_vs_ts_CCTA_dumaxp6.svg"))
        (caption
         "Text pertaining to both graphs from a sexp, " (ref "fig:sa")
         " and " (ref "fig:sb") "." (label "figs12")))
#+END_SEXP



* Bibliography

# FOR LATEX
#+BIBLIOGRAPHY: /home/arnold/bib_pdf/main_bibliography.bib IEEEtran

# FOR HTML
# #+BIBLIOGRAPHY: /home/arnold/bib_pdf/main_bibliography.bib /home/arnold/bib_pdf/ieee.csl limit:t
