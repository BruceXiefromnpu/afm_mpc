% Created 2018-02-21 Wed 19:30
% Intended LaTeX compiler: pdflatex
% \documentclass[11pt]{cu_thesis}
\documentclass[journal,12pt,twocolumn,twoside]{IEEEtran/IEEEtran}
% \documentclass[journal,12pt,onecolumn,draftclsnofoot,,twoside]{IEEEtran/IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
% \usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[inkscapelatex=false, inkscapepath=svgsubpath]{svg}
\usepackage{subfigure}
\usepackage{xspace, dsfont}
\usepackage{mathtools}
\usepackage{multirow}

\newcommand{\Dm}{\ensuremath{\mathcal{D}_{-} }\xspace}
\newcommand{\U}{\ensuremath{\mathcal{U} }\xspace}
\newcommand{\DU}{\ensuremath{\Delta \mathcal{U} }\xspace}
\newcommand{\Q}{\ensuremath{\mathcal{Q} }\xspace}
\newcommand{\R}{\ensuremath{\mathcal{R} }\xspace}
\newcommand{\Hh}{\ensuremath{\mathcal{H} }\xspace}
\newcommand{\du}{\ensuremath{\Delta u }\xspace}
\newcommand{\dU}{\ensuremath{\Delta \mathcal{u} }\xspace}
\newcommand{\Gd}{\ensuremath{\tilde G }\xspace}
\newcommand{\Ad}{\ensuremath{\tilde A }\xspace}
\newcommand{\Bd}{\ensuremath{\tilde B }\xspace}
\newcommand{\Cd}{\ensuremath{\tilde C }\xspace}
\newcommand{\xd}{\ensuremath{\tilde \xi }\xspace}
\newcommand{\Qd}{\ensuremath{\tilde Q }\xspace}
\newcommand{\Rd}{\ensuremath{\tilde R }\xspace}
\newcommand{\x}{\ensuremath{\xi }\xspace}
\newcommand{\xdss}{\ensuremath{\tilde \xi_{ss} }\xspace}
\newcommand{\xde}{\ensuremath{\tilde \xi_{e} }\xspace}
\newcommand{\xo}{\ensuremath{\hat \xi }\xspace}
\newcommand{\yr}{\ensuremath{\nu_{r} }\xspace}
\newcommand{\y}{\ensuremath{\nu} \xspace}
\newcommand{\dd}{\ensuremath{\Delta }\xspace}
\newcommand{\ub}{\ensuremath{\bar{u} }\xspace}
\newcommand{\ubp}{\ensuremath{\bar{u}^+ }\xspace}
\newcommand{\ubm}{\ensuremath{\bar{u}^- }\xspace}
\author{arnold}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={arnold},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 24.4.1 (Org mode 9.1.4)}, 
 pdflang={English}}
\begin{document}



\section{Introduction}
\label{sec:orge362f71}

In the context of CS, we are interested in rapidly moving the AFM stage between setpoints. The setpoints define either discrete measurement locations or the start of a new \(\mu\) -path scan. In earlier work, we found while exploring the limits of achievable with plain linear feedback that the change in the control input, \(\Delta u(k)\) was the limiting factor. We  \cite{braker_application_2017}, \cite{braker_fast_2017} took the viewpoint of trying to achieve a stable system for a equivalent given feedback gain in the face of rate-of change saturation. The methods we chose for doing this were using model predictive control (MPC) and tracking an optimal trajectory generated by solving a contrained, linear quadratic regulator problem (CLQR). In both cases, we considered a standard quadratic cost function

\begin{align}
V(z,v) &= \min_{v} z_{N}Q_{p}z_{N} + \sum_{i=0}^{N-1}z_{i}^{T}Qz_{i} + v^{T}_{i}Rv_{i}\\
 \text{s.t.}&\\
z_{i+1} &= Az_{i} + Bv_{i}\\
z_{0} &= x_{k}\\
|v_i - v_{i-1}| &\coloneqq |\Delta v(i)| \leq (\Delta u)_{max}
\label{eqn:opt}
\end{align}


The essential difference between the MPC scheme and the trajectory tracking scheme is that the optimzition in MPC solved repetaly online, and the control input given to the system is \(v(0)\). In the trajectory tracking scheme, the optimization is solved offline and the resulting optimal input trajectory is fed to the system in a feedforward manner while state feedback tracks the optimal state sequence. In both cases, the weight \(Q, R)\) were chosen via an inverse optimal control problem, such that the associated linear feedback (in the infinite horizon, unconstrained LQR problem) would place the poles with the desired damping. 

It was our conclusion that both methods are effective at extending the stable range of a given \((Q,R)\) pair in the face of \(\Delta u\) saturation. The attractiveness of MPC here is that it does not depend on defining a list a setpoints to visit a-priori. The downside to MPC is that to significantly expand the region of rechable setpoints requires a large control horizon. Our MPC implementation used the Fast Graident Method (FGM) to solve the quadratic program associated with \eqref{eqn:opt}. Unfortunately, the convergence rate of the FGM depends heavily on the condition number of the Hessian matrix of the QP. Several factors contribute to a poorly conditioned Hessian matrx: (1) long control horizon (2), aggressive (Q,R) weights. The other factor limiting the horizon length in MPC is that the problem size grows, making the QP more difficult to solve within the required sampletime. 

The question which naturually arises from our prior work and which is the main topic of this study, is "how much \emph{time} is actually saved with either MPC or CLQR tracking?" In essence, the reachable set of setpoints using pure linear feedback can be expanded by de-rating the linear feedback gain. While we might expect this to result in a slower settling time, the question we seek to answer is \emph{how much slower}? In short, are the more complicated methods worth it?

A second related question is \emph{if you're going to go through the trouble of generating and tracking an optimal trajectory, why not track the time-optimal trajectory?}

We will answer both of these questions in this paper. 




\section{System Modeling}
\label{sec:orgbc45dd3}
\subsection{Modeling}
% \begin{figure}
%   \includegraphics[scale=0.45]{figures/exp_setup.pdf}
%   \caption{Experimental setup}
%   \label{fig:exp_setup}
% \end{figure}
\begin{figure*}
  \centering
  \begin{minipage}{0.45\textwidth}
  \includesvg[scale=01]{figures/G_uz2pow.svg}
  \caption{Frequency response from control input to high voltage signal (blue) and from high voltage input to stage position (red). The red curve is the FRF for both the vibrational and drift dynamics.}
  \label{fig:powfrf}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
  \centering
  \includesvg[scale=0.8]{figures/frf_xdir.svg}
  \caption{Frequency response of the piezo stage in the $x$-direction. The dashed black curve is a 12th order model fit to the data using a subspace realization method.}
  \label{fig:frf_xdir}
\end{minipage}
\end{figure*}
The AFM in our lab consists of an Agilent 5400 which has been retrofited with an nPoint NPXY100A piezo stage, which provides lateral movement of the sample. which is driven by a C300 signal conditioner/amplifier. The C300 amplifies the low voltage ($\pm~10$ volts) control inputs to a voltage signal which drives the piezo stage and provides signal conditioning for the capacitive position sensors in the stage. All control logic is programmed into a Xilinx FPGA in a cRIO 9082 from National Instruments.


To keep the discussion manageable, we will concentrate the discussion to the $x$-direction.
We call the transfer function from the low voltage control input $u$ to high-voltage output $V_{h}$ $G_{pow}$, whose frequency response is shown as the blue curve in Fig.~\ref{fig:powfrf}. The high voltage output of $G_{pow}$ drives the piezo stage and ultimately results in a position displacement, which we will refer to as $G_{stage}$. This frequency response is shown as the red curve in Fig.~\ref{fig:powfrf}. From our model fitting efforts, it is apparent that $G_{stage}$ has a low frequency real pole-zero pair around 50~Hz, which acts as a first order drift model. In Section~\ref{sec:mintime}, it will be useful to decompose the stage dynamics as $G_{stage} = G_{drift}G_{vib}$. 
Thus, the complete transfer function from low voltage control to position displacement is given by the series connection
\begin{align}
  \frac{Y(z)}{U(z)} &= G_{stage}G_{pow}\\
                    & =G_{vib}G_{drift}G_{pow}
\end{align}
These experimental frequency responses are obtained using a sine dwell (single frequency at a time) method programmed into the cRIO. In characterizing the power amplifier (C300) limitations in Section~\ref{sec:powcharct}, it will be useful to have measurements of the C300 high voltage output and current directly. To obtain these measurements, the C300 drive signal is re-routed as shown in Fig.~\ref{fig:c300_meas}. The voltage divider output provides a (scaled) measurement of the C300 output voltage and is given by
\begin{equation}
V_X = \frac{R_1 + R_2}{R_2}V_{div}
\end{equation}
Note that the impedance of the divider is high (about $32.5\text{M}\Omega$) to avoid perturbing the amplifier output.

 A small, $0.1~\Omega$ resistor on the return side of the piezo provides a current measurement. The voltage across this resistor is amplified by a simple op-amp circuit so that
\begin{equation}
I_{X} = \frac{V_{op}}{K_{op}R_{\text{sense}}}
\end{equation}
where $K_{op}$ is the gain of the operational amplifier.

Note the large amounts of phase lag in both $G_{pow}$ and $G_{stage}$. This is due to the C300 including its own DSP which cannot be turned off, even when run in open loop mode. To fit parametric models to these transfer functions, we use least squares method to fit $G_{pow}$ and a subspace based method to fit $G_{stage}$. 
The total model $G$ is depicted as the black dashed curve in Fig.~\ref{fig:frf_xdir} which is a state space model with 22 states, 9 of which model transport delay.

\begin{figure}
  \includegraphics[width=0.5\textwidth]{figures/c300_measurement_schematic.pdf}
  \caption{Schematic of the augmented high voltage output measurement and current measurement used in characterizing the C300.}
  \label{fig:c300_meas}
\end{figure}

\subsection{Power Amplifier Characterization and Limitations}\label{sec:powcharct}
The high voltage output of the C300 is current limited to 100 mA. Because the piezo stage largely presents as a capacitive load to the power amplifier, this roughly translates to a rate of change limitation on the voltage control signal since
\begin{equation}
\dot v_{h} = \frac{1}{C} i_c(t)
\end{equation}
To determine what the voltage rate of change limit is, we implemented a low-side (which prevents issues with a large common-mode voltage) current measurement. This was done by re-routing the power amplifier return line from the piezo stage through a $0.1~\Omega$ current sensing a resistor. The voltage drop across this resistor was amplified with a simple op-amp circuit.

\begin{figure*}[htbp]
  \begin{minipage}{0.48\textwidth}
\centering
\includesvg[width=.9\linewidth]{figures/stage_frfs_all}
\caption{\label{fig:org8f9b1d0}
Frequency responses for the stage and power amplifier in the X-direction.}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\centering
\includesvg[width=1.1\linewidth]{figures/stage_vs_cap}
\caption{\label{fig:orgc576458}
  Frequency responses for the stage and power amplifier in the X-direction.}
\end{minipage}
\end{figure*}

This new measurement allows us to measure the frequency responses between several interesting points, enumerated in Table~\ref{tab:TFS} and shown in Figure~\ref{fig:org8f9b1d0}.

\begin{table}
  \centering
  \begin{tabular}{ll}
    name & description\\
    \hline
    \(G_{y_{X},u_{X}}\) & \multirow{2}{2.5in}{T.F. from low voltage control to stage position.}\\
    &\\
    \(G_{y_{X},u_{X}}\) & \multirow{2}{2.5in}{T.F. from high-voltage C300 output voltage control to stage position.}\\
    &\\
    \(G_{I_{X},u_{X}}\) & \multirow{2}{2.5in}{T.F. from low voltage control to C300 output current.}\\
    &\\
    \(G_{I_{X},V_{X}}\) & \multirow{2}{2.5in}{T.F. from high-voltage C300 output to C300 output current.}\\
  \end{tabular}
  \label{tab:TFS}
\end{table}

It is tempting to think that we ought to constrain the rate of change of the power amplifier voltage output, since this is the voltage actually running through the piezo. There are two difficulties with this approach. First, \(G_{V_{x},u_{x}}\) rolls off at about 250~Hz, which means that such a constrain will lead to a constraint on the states of \(G_{V_{x},u_{x}}\). Second, the transfer function \(G_{I_{x}, V_{X}}\) has a break frequency at about 700~Hz, where it begins increasing at 40~dB per decade. Thus, for control signals with high frequency content, a simple rate of change requirement would \emph{under-estimate} the actual current draw.

However, if we consider \(G_{I_{x},u_{x}}\) we see that it can be upper-bounded by a pure derivative
In other words, 
\begin{equation}
G_{I_{X},u_{X}}(e^{j\omega T_{s}}) \leq k_d(z-1), \quad \forall \omega \in[0, \pi/T_s]
\end{equation}
where, from our experimental data, $k_d=0.506$. The bound $k_d(z-1)$ is shown as the dotted-black curve in Fig.~\ref{fig:orgc576458}. Thus, for all inputs,
\begin{align}
|I_{X}(k)| &\leq k_d(u_X(k) - u_X(k-1)|
\end{align}
Thus, we need to enforce
\begin{equation}
|\Delta u_X(k)| \leq I_{\text{max}}/k_d = 0.198. 
\end{equation}
We note that this condition is more conservative than is strictly necessary. For inputs with significant frequency content above 1000~Hz, a pure derivative overestimates the amount of actual current draw. Ideally, we would develop a parametric model of \(G_{I_{x},u_{x}}\) and enforce a constraint on the output of that model. However, such an approach renders the constraint set for $u_X$ complex and is it not feasible to solve that problem using the fast gradient method. Moreover, it is likely ill advised to allow the controller to heap control energy above 1000 Hz anyway, as we don not model the modes of the stage past that frequency anyway. 

\subsection{Model Fitting}
To obtain a parametric model of $G_{X,u_X}$ for control design requires several steps. We obtain a preliminary model using an Eigenspace Realization methods. These methods will not generally produce a model with poles at $z=0$. Thus, the delay in the frequency response is divided out out before passing it to the ERA algorithm. the ERA does a fair job of identifying the resonances and anti-resonances. However, it gets the relative degree wrong which, in our experince, causes sever robustness problems when a a state estimator is added to the system.

Thus, the second step is to use the model generated by the ERA as the initial guess to a non-linear least squares problem \cite{sidman_parametric_1991} which minimizes the ratio of the logarithm of the experimental frequency response to that of the model. Though Sidman et al. develop the idea for a continuous time models, their strategy is easily adopted to fit a discrete time model. The model is parametrized by first and second-order factors
\begin{equation}
  \hat{G}(z|\theta) =k \frac{\prod (z-b_i) \prod(z^2 +b_jz + b_{j+1})}
  { \prod_{l=1}(z-a_l) \prod(z^2 +a_mz + a_{m+1})}z^{-p}
\end{equation}
Note that the model includes a fractional delay $z^{-p}$. This allows us to include the delay as a term in the decision variable and obviates the need to optimize over integers. This is further beneficial because we are not guaranteed that the latency from input to output is actually an exact integer and allowing a fractional delay helps the optimization to more accurately match the phase. The optimization is given by
\begin{align}
\min_{\theta} \sum_{i=1}^M| \log(G(e^{j\omega_iT_s})) - \log(\hat{G}(e^{j\omega_iT_s}|\theta))|^2
\label{eqn:logfit}
\end{align}
where $\omega_i$ is each frequency in the experimental frequency response. Because the logarithm of the products is the sum of the logs, the Jacobian for this cost function is surprisingly easy to calculate. Details can be found in \cite{sidman_parametric_1991}.

In this work, we do not model the modes above 1100~Hz. Thus, the optimization \eqref{eqn:logfit} is only done over frequency up to 1100~Hz. 


\section{Control Setup}
\subsection{The Incremental Form}
In the optimizations we consider, it will often be useful to work with an incremental form of \(G\) which has as its input \({\Delta u(k)\coloneqq u(k)-u(k-1)}\), rather than \(u\), which is defined by augmenting \(G_p\) with an state \x\(_{\text{u}}\)(k) such that
\begin{equation*}
  \x_u(k) = u(k-1).
\end{equation*}
It follows that
\begin{subequations}
\begin{align}
  \xd(k+1)
  &=
    \begin{bmatrix}
      A & B\\ 0 & I
    \end{bmatrix}
    \xd(k)
    +
    \begin{bmatrix}
      B\\I
    \end{bmatrix}
  \Delta u(k) \\
  \y(k) & = \begin{bmatrix}C & 0\end{bmatrix}\xd(k)\\
  \xd(k)& \coloneqq \begin{bmatrix}\x(k)\\\x_u(k) \end{bmatrix}\\
  \xd(0) & = \begin{bmatrix}\x(0)\\u(-1)\end{bmatrix}. \label{eqn:x0_aug}
\end{align}\label{eqn:ssdelta}%
\end{subequations}
We call this system \(\Gd = \{\Ad, \Bd, \Cd, 0\}\), which has \({\tilde{n}_s=50}\) states.
To solve the setpoint tracking problem, we work in the error
coordinates of \(\Gd\).
For an arbitrary reference \(\y_r\), in steady state we have \({\du_{ss}=0}\) and \(\xdss =N_{\xi}\y_r\) where \({N_{\xi}\in\mathds{R}^{\tilde{n}_s\times n_u} }\) is found by solving
\begin{align}
  \begin{bmatrix}N_{\xi} \\ N_u\end{bmatrix} &=
\begin{bmatrix}I-\Ad & -\Bd\\\Cd & 0\end{bmatrix}^{-1}\begin{bmatrix}0\\ I\\\end{bmatrix}\label{eqn:nxnu},
\end{align}
which, due to the augmented pole at $z=1$, will give \(N_u\equiv 0\). 
The error state, \({\xde(k)=\xd(k) - \xdss}\) has dynamics
\begin{align}
  \xde(k+1) & = \Ad\xd(k) + \Bd\dd u(k) - \xdss \nonumber\\
            & = \Ad \xde(k)   + \Bd \dd u(k)\nonumber
\end{align}
because $\xdss$ is in the nullspace of $(I - \Ad)$.

\subsection{Observer Design}

We use the method outlined in \cite{doyle_robustness_1979}.

\section{The Optimal Control formulations}
We want to look at a few different ways of driving the stage from point to point as rapidly as possible, yet still be practical. Inspired by our past work, we will compare several methods through both simulation and experimental studies. These methods are
\begin{itemize}
\item\emph{Discrete time, minimum time optimal control (DTMT)}
\item\emph{Saturated Linear state feedback (SLF)} The basic idea here to use standard linear state feedback which is saturated (on $\Delta u$) but to de-rate the design such that the closed-loop system is demonstrably stable up to a certain reference size. 
\item\emph{Constrained Model Predictive Control (MPC)} The goal with MPC is that, instead of fully de-rating the design to account for the slew rate constraint, to directly account for the constraint as part of the control law itself. Do to limitations on the implementation, MPC must still be de-rated to some extent to be implementable, since the length of control horizon needed to achieve stabilty over the full range of the stage becomes large for an aggressive design.
\item\emph{Constrained, Finite horizon LQR (CLQR)} The optimization is the same as the MPC optimization, just over a much longer horizon. Similarly to the DTMT idea, this would be implemented in a feedforward/tracking configuration. However, the broader goal of considering this scheme is that it shows how much optimality we have sacrificed with a relatively short horizon in MPC.
\end{itemize}

The last three control schemes can be described the optimization
\begin{align}
V(z,v) &= \min_{v} z_{N}Q_{p}z_{N} + \sum_{i=0}^{N-1}z_{i}^{T}Qz_{i} + v^{T}_{i}Rv_{i}\\
 \text{s.t.}&\\
z_{i+1} &= Az_{i} + Bv_{i}\\
z_{0} &= x_{k}\\
|v_i - v_{i-1}| &\coloneqq |\Delta v(i)| \leq (\Delta u)_{max}.\label{eqn:optconst}
\end{align}
In the case of MPC, the control at the current time step as taken $v_0$, the rest of the optimal controls are thrown away and the optimization is repeated at the next sampling instant. Here, we consider control horizons ranging from $N=4$ to $N=20$. In the case of CLQR, we consider a much longer control horizon of $N=400$. The idea then is to apply the optimal control to the system and track the optimal system output. For SLF, we set $N=1$ and eliminate the constraint \eqref{eqn:optconst}. Because we have taken $Q_p$ as the solution to the discrete algebraic Riccatti equation, this is equivalent to the standard infinite horizon LQR problem. In the case of CLF $\Delta u_k$ is saturated in software, which is more predictable than allowing it happen in hardware and ensures that the control applied to the plant matches the control seen by the state estimator.

In CLQR, MPC and CLF,  the state weight $Q$ is selected via an inverse optimal control problem to yield good damping and to cancel the real pole-zero pair near 50~Hz. For MPC and CLF, we treat control weight $\gamma$ as the primary tuning parameter. In both cases, a larger $\gamma$ yields a larger maximum step size that can be tracked. Essentially, we can view each control 

\subsection{The minimum-time control problem in discrete-time}\label{sec:mintime}
\label{sec:org6d1d6b6}
In discrete-time, the minimum-time control problem can be stated as \cite{chen_minimumtime_cca}
\begin{align}
\min_{u(0), u(1),\dots,u(N-1)} & N\\
\text{s.t.}&\\
x_{k+1} & = Ax_{k} + Bu_{k}\\
x_{N} & = x_{f}\\
u_{k}&\in \mathds{K},~k=0,\dots,N-1\\
x_{k} &\neq x_{f},~k=0,\dots,N-1.
\end{align}
where $x_f$ is the desired final target state. 
For a given control sequence $\{u_0,\dots, u_{N-1}\}$, and an initial condition $x_0$, the state $x_N$ at the final time is given by
\begin{equation}
X_N = A^Nx_0 + \sum_{i=0}^{N-1}A^{N-1-i}Bu_i.
\end{equation}
Practically, the problem can be solved using a bisection method which searches for the smallest feasible \(N\). In these cases, the bisection search solves sub-problem given by
\begin{align}
\min_{U}& || x_{f} - x_{N}||\\
\text{s.t.} &\\
x_{k+1} & = Ax_{k} + Bu_{k}\\
u_{k}&\in \mathds{K},~k=0,\dots,N-1\\
\end{align}
For a given \(N\), if \(||x_{f} - x_{N}|| < \text{TOL}\), the sub-problem returns successful, otherwise it fails. The goal then is to find a the smallest \(N\) that succeeds. 

It is also worth pointing out that the solution to this problem, in contrast to continuous time systems is not in general bang-bang CITE.

When we consider comparing the settling time of our LQR inspired methods to the time-optimal solution, we need to be careful.
The reason is that the time optimal solution requires all the states to have reached steady at $x_f$. Consequently, the total move, if we compute the time-optimal trajectory for $G$, will be dominated by the slow pole at 220 Hz. This is illustrated in Fig.~\ref{fig:slowpz_to}.

\begin{figure}
  \centering
  \includesvg[scale=1]{figures/timeopt_slowpz_illustrate_y.svg}
  \includesvg[scale=1]{figures/timeopt_slowpz_illustrate_u.svg}
  \caption{The problem with computing the time-optimal trajectory when the model has the slow PZ-pair.}
  \label{fig:slowpz_to}
\end{figure}
In some sense, the slow pole-zero pair is a first order drift model, so we call it $G_{drift}$. Then, the total transfer function from the control to the piezo stage position can be factored as $G(z) = G_{drift}\hat{G}(z)$. The idea then, is to compute the time-optimal trajectory for $\hat{G}(z)$. This results in optimal trajectories for the control input, $u^*$ and plant output $y^*$ for $\hat{G}$. That optimal control sequence is will then be run through a feedforward filter which inverts the dynamics of $G_{drift}$. The scheme is illustrated in Fig.~\ref{fig:bd_ff_to}
\begin{figure}
  \centering
  \includegraphics[scale=0.4]{figures/bd_ff_timeopt.pdf}
  \caption{Time optimal trajectory with selected plant inversion.}
  \label{fig:bd_ff_to}
\end{figure}


\section{Quantifying the time savings (if any) of MPC and d-rated linear feedback}
\label{sec:org7edf36d}
The goal of this section is to quantify the time savings (if any) of using MPC vs SLF. While is is certainly true that for a given feedback gain (i.e., $(Q,R)$ pair), we can extend the stable range of setpoints. However, that does not tell us how much time we save with that strategy. To be able to make this comparison, we need a way to decide when a trajectory is unstable, or more generally, unacceptable. The most niave way to this would be to just look at the settling time over a sufficiently long simulation: if the trajectory never settles into the settle boundary, we decide the system was unstable for that setpoint size. The trouble with this is that there is a middle ground, where the trajectory will actually settle, but spends a lot of time oscillating (in some non-linear fashion) before it gets there. This is illustrated in Fig. REF.


\subsection{Rejection Metrics}
There are several ways we might think about doing this. 
For a given $\gamma$, we need a way to decide if the trajectory which results from either SLF or MPC is acceptable for a given setpoint size.

Ultimately, we have decided to do is to compare the trajectory resulting from MPC or SLF with the one from CLQR: if the settling time is greater than 20\% of the CLQR trajectory, we decide that the current setpoint was too large.


\begin{enumerate}
\item We start with a nominal \((Q,R)\) pair.
\item We determine how large we must make \(\gamma R\) to visit a certain size of setpoint. In general, the larger \(\gamma\) is, the larger the maximum setpoint we can visit is. This is what I mean by "de-rating" the feedback gain and is illustrated below in Figur.
\end{enumerate}


Note that each point in that plot was generated by simulated the linear feedback law with saturation starting from a very small setpoint and incrementing larger (by 0.1 I think) until the output becomes unstable. 

So the questions I want to answer are:
\begin{enumerate}
\item Given a maximum setpoint \(ref_{max}\), how much time do we \textbf{loose} by making \(\gamma\) large? Said another way, what is the time penalalty for needing to visit larger setpoints (since this implies that \(K\) must be "smaller")?
\item How does this time compare to what we can acheive with MPC?
\end{enumerate}


The way I think it makes sense to think about these questions is to compare the settling times to the optimal, constrained finite horizon (CLQR) open-loop settling time. At least for a given quadratic cost, that is typically the best settling time we can hope to achieve, and we won't run into the problems with MPC where need a larger control horizon to get stability. 

\begin{figure}
  \centering
  \subfigure[The increase in maximum achievable setpoint as the control weight $\gamma$ increases for both saturated linear feedback different MPC control horizons.
  \label{fig:maxsp_by_gam}]
  {\includesvg[width=3in]{figures/maxref_vs_gamma_dumaxp6.svg}}
\hfill
\subfigure[Comparison of settling time the minimum-time solution and the CLQR solution.
\label{fig:ts_clqr_to}]
{\includesvg[width=3in]{figures/clqrTimeOpt_sp_vs_ts_CCTA_dumaxp6.svg}}
% \caption{both}
\end{figure}

The result of running a parameter sweep this way is shown in Fig.~\ref{fig:maxsp_by_gam}. What the figure shows is, for CLF, and several values of the MPC control horizon, the maximum setpoint that can be tracked for a given control weight $\gamma$. In the figure $\gamma$ ranges from 10 to 5000 in XX increments. For each value of $\gamma$, we performed successively larger step-input simulations between and 12 v. The $y$-axis value indicates that that value of reference resulted in a deteriorated or unstable trajectory, and is thus the largest track-able setpoint for the given gamma.

\section{Time Savings Analysis}
The goal of doing this is to essentially look at several cross sections Fig.~\ref{fig:maxsp_by_gam} and look at how the settling time changes between CLF and different MPC control horizons \emph{for a given desired maximum setpoint.}

Here, we choose several desired $r_{max}$ values and consider how much time is saved over the time optimal solution for the different strategies. We choose $r_{max}$ as 2.5, 5.0 and 10. These values are illustrated in Fig.~\ref{fig:maxsp_by_gam} by the dotted black lines. Where those dotted black lines cross the various curves indicates the $\gamma$ that is required.

\begin{figure*}
  \begin{minipage}{0.32\textwidth}
    \includesvg[width=1.2\textwidth]{figures/perc_increase_rmax2p5.svg}
  \end{minipage}
    \begin{minipage}{0.32\textwidth}
    \includesvg[width=1.2\textwidth]{figures/perc_increase_rmax5.svg}
  \end{minipage}
  \begin{minipage}{0.32\textwidth}
    \includesvg[width=1.2\textwidth]{figures/perc_increase_rmax10.svg}
  \end{minipage}
  \caption{The percentage increase over the time-optimal solution for CLF (orange), the CLQR solution (blue) and the MPC strategy for control horizons ranging from $N=4$ to $N=20$. }
  \label{fig:perc_inc}
\end{figure*}
Our takeaway from this study is that there appears to very little benefit in terms of time saved for implemented the CLQR or MPC control strategies. The largest difference in the percent increase is only in the range of 10\%, and for the smaller $r_{max}=2.5$, this difference is even smaller. 

\section{Experimental Comparison}
Our simulation results indicate that we may as well use CLF or track the time-optimal trajectory, if we can get away with it. But what about the real world?

\newpage

% \FloatBarrier
\section{Imaging Results}
In these section, we demonstrate using the time-optimal tracking method to actually acquire images via $\mu$-path based CS.
\begin{figure}
  \centering
\includegraphics[scale=1]{figures/5micron_rasterscans_v2.eps}
\includegraphics[scale=1]{figures/5micron_csscans_v2.pdf}
\caption{RESULT!}
\label{fig:imaging}
\end{figure}

\section{Bibliography}
\label{sec:org5b4a114}

\bibliographystyle{IEEEtran}
\bibliography{/home/arnold/bib_pdf/main_bibliography.bib}
\end{document}